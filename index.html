
    <html>
    <head>
        <title>Reddit Hot Posts Report</title>
        <style>
            table { width: 100%%; border-collapse: collapse; }
            th, td { border: 1px solid black; padding: 8px; text-align: left; }
            th { background-color: #f2f2f2; }
        </style>
    </head>
    <body>
        <h2>Reddit Hot Posts from Last 24 Hours</h2>
        <table>
            <tr>
                <th>Subreddit</th>
                <th>Title</th>
                <th>Score</th>
                <th>URL</th>
                <th>Comments Count</th>
                <th>Posted UTC</th>
                <th>Selftext</th>
                <th>Comments</th>
            </tr>
    
            <tr>
                <td>hardware</td>
                <td>First GeForce RTX 5070 Ti discovered with reduced ROP count: 88 instead of 96 - VideoCardz.com</td>
                <td>262</td>
                <td><a href="https://videocardz.com/newz/first-geforce-rtx-5070-ti-discovered-with-reduced-rop-count-88-instead-of-96">https://videocardz.com/newz/first-geforce-rtx-5070-ti-discovered-with-reduced-rop-count-88-instead-of-96</a></td>
                <td>92</td>
                <td>2025-02-23 05:04:51</td>
                <td>I'm beginning to think it's 5% instead of 0.5%</td>
                <td><ul><li><b>Account34546 (Score: 153):</b> Not enough silicon for the AI business so they fed gamers with faulty chips? This certainly does not look good, especially in cooperation with current market price gymnastics.</li><li><b>RandomGuy622170 (Score: 109):</b> Stay the fuck away from these cards. Seriously. Do not give this greedy ass company your money. Between the piss poor performance uplift to the price to the damn power connectors melting to now crippled cards being sold, this entire launch has been an unmitigated shit show.</li><li><b>MiloIsTheBest (Score: 41):</b> Lol well that fkn sucks. 


It's just one more thing for this series. 


I hope we look back on this time and are able to say what a horrific shitshow this was and *thank God it's over*.


If it ever ends.</li><li><b>Surfacing555666 (Score: 30):</b> AMD has such a massive chance to seize on nvidia losing customer trust right now, I hope someone there is speaking up about it</li><li><b>kimmyreichandthen (Score: 67):</b> NVIDIA is actually scamming us. I thought maybe I would buy the 50 series secondhand in the future, but these news killed that hope. What a fucking joke.</li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>If you have a 4080/90 from launch, verify your 12VHPWR voltage under load in HWiNFO</td>
                <td>76</td>
                <td><a href="https://www.reddit.com/r/hardware/comments/1ivyrg0/if_you_have_a_408090_from_launch_verify_your/">https://www.reddit.com/r/hardware/comments/1ivyrg0/if_you_have_a_408090_from_launch_verify_your/</a></td>
                <td>25</td>
                <td>2025-02-23 01:37:05</td>
                <td>I recently came across a comment in one of the 12VHPWR threads that some connectors on cables have shown degradation over time. I have a 4090FE from around launch connected to a Corsair RM1000x (2021) using the official Corsair Type-4 12VHPWR cable so I started monitoring mine in HWiNFO and found that even at 70% PL, the GPU 16-pin HVPWR Voltage would drop from 12.XXV at idle to as low 11.70V. I checked my connector and found no visible damage but the voltage drops continued even after reseating</td>
                <td><ul><li><b>Kougar (Score: 15):</b> GPU-Z also provides 16-pin power connector voltage & power readouts</li><li><b>Raiden85OCUK (Score: 9):</b> My Zotac 4090 Extreme Airo from around launch, connected to a Corsair AX1600i PSU using a 4x 8 pin (only 3 cables connected since launch) to 12VHPWR CableMod extension type cable. I have checked my cable with a thermal camera, and it's running pretty cool, pretty much the same as when I installed it. This PC also runs 24/7 with a few thousand gaming hours on this card, and so far it's been rock solid.

GPU 16 pin HVPWR drops to 11.775V at load, 12.1V idle.

Hwinfo image of the voltages.

[https://i.imgur.com/O2412Xd.jpg](https://i.imgur.com/O2412Xd.jpg)

Thermal image, it's been around the same temps since launch.

[https://i.imgur.com/M3EeqJK.jpg](https://i.imgur.com/M3EeqJK.jpg)</li><li><b>Savage4Pro (Score: 5):</b> Ran shadertoy (like furmark full screen) for ~9mins: https://www.shadertoy.com/view/Wt3XRX

Had to set power to +33% and hit 573W on my 4090 and lowest my 12V reading got was 11.989V. Not to warm to touch either. Otherwise at 450W stays at 12.022ish.

Full stats here. https://i.imgur.com/u86mNJa.png</li><li><b>Stranger_Danger420 (Score: 7):</b> I’ll check this tonight or tomorrow. Been watching this at idle here and there and always well over 12v at idle at least.</li><li><b>gdnws (Score: 2):</b> One thing I also like to do is compare the vhpwr voltage to the pcie +12 input voltage. The two voltages are always within a few mv of each other but the vhpwr input is always higher than the pcie, at least with mine. I don't tend to care too much the exact voltage, as long as it is within spec, more that the vhpwr voltage never goes below the pcie.</li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>[buildzoid] Innocent capacitor blamed for ASUS RTX 5090 Astral catching fire</td>
                <td>149</td>
                <td><a href="https://www.youtube.com/watch?v=aHRlYQas4xw">https://www.youtube.com/watch?v=aHRlYQas4xw</a></td>
                <td>22</td>
                <td>2025-02-22 21:41:00</td>
                <td></td>
                <td><ul><li><b>hardware-ModTeam (Score: 1):</b> Reminder to commenters: 

* Low effort comments, memes, or jokes will be removed</li><li><b>None (Score: 59):</b> [removed]</li><li><b>doscomputer (Score: 15):</b> weird things happening in these comments</li><li><b>None (Score: 1):</b> [removed]</li><li><b>wtallis (Score: -74):</b> Buildzoid seems mystified why people have the impression that capacitors can fail. Is he too young to remember capacitor plague, or is he just being weirdly narrow-minded and assuming that everyone knows the difference between solid polymer caps and ones with a liquid electrolyte?</li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>AMD Navi 48 RDNA4 GPU has 53.9 billion transistors, more than NVIDIA GB203</td>
                <td>284</td>
                <td><a href="https://videocardz.com/pixel/amd-navi-48-rdna4-gpu-has-53-9-billion-transistors-more-than-nvidia-gb203">https://videocardz.com/pixel/amd-navi-48-rdna4-gpu-has-53-9-billion-transistors-more-than-nvidia-gb203</a></td>
                <td>187</td>
                <td>2025-02-22 15:28:39</td>
                <td></td>
                <td><ul><li><b>funny_lyfe (Score: 186):</b> People do understand that they probably added more cache to lower the speed of RAM needed? nVidia is paying for GDDR7 and AMD for GDDR6 which is dirt cheap right now.</li><li><b>SceneNo1367 (Score: 67):</b> How can they have higher density than nvidia and higher clocks at the same time?</li><li><b>Noble00_ (Score: 50):</b> Really interesting turn of events if confirmed confirmed. We went from RDNA3 having mediocre transistor density to being competitive to Ada/Blackwell.

Navi33 has 13,300 million transistors, is 204mm2, with a 65.2M / mm2 density.  
Navi31 has 57,700 million transistors, is 529mm2 overall, with a 109.1M / mm2 density.  
\> GCD only has 45,400 million, 304.35mm2, with a 150.2M / mm2 density.

Looking forward to analysis on release</li><li><b>DeeJayDelicious (Score: 20):</b> If Nvidia can achieve better performance with fewer transitors, surely this is a win for Nvidia?</li><li><b>fatso486 (Score: 18):</b> Wow, that's such a far cry from older AMD chips! The Navi 23, with its 11 billion transistors, performs about the same as the RTX 4060, despite the latter having almost double the transistors at 19 billion.

Why is there a perception that the N48 is much cheaper to manufacture than the RTX 5080? The only major cost difference I see for NVIDIA is the use of GDDR7 instead of GDDR6. If I'm not mistaken, the price is around $8 per GB for GDDR7 versus $5 per GB for GDDR6—meaning about a \~$45 difference for a 16GB card.

What am I missing? Did the shift to GDDR7 even give NVIDIA **ANY** advantage over Ada? Could there be a difference in board costs?</li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>[GamersNexus Consumer Advocacy] Second-Hand Scams on Amazon</td>
                <td>69</td>
                <td><a href="https://www.youtube.com/watch?v=EYMdWqIPRWI">https://www.youtube.com/watch?v=EYMdWqIPRWI</a></td>
                <td>24</td>
                <td>2025-02-22 22:30:58</td>
                <td></td>
                <td><ul><li><b>DryPriority1552 (Score: 33):</b> Some asshole probably got 1000w PSU for 5090 and put their old PSU in to test their luck....  annnd it worked since warehouse workers are not guaranteed to be tech savvy and know the difference between PSUs. Very likely scenario in SFF space.</li><li><b>HorrorBuff2769 (Score: 21):</b> I had Amazon send me a “new” psu in a plastic bag with no cables.</li><li><b>aminorityofone (Score: -6):</b> If GN went after amazon like they did with all the other brands i would care. Otherwise, MEH. Where is that fire and passion with Ek, newegg, that computer builder company (sorry i forget the name ha!), LTT, Honey... etc. Where is the lawyer? Why isnt this on the main channel?</li><li><b>SmileyBMM (Score: 0):</b> I mostly don't buy things from Amazon anymore because of this issue. Sure other stores have longer shipping times, but I don't have to worry about fake/damaged goods.</li><li><b>doscomputer (Score: -6):</b> wow, the oldest trick in the book, people used to do this with newegg too, even worse at time, just return an item with brick in the box and 90% of the time they never check

I don't buy his argument that this wasn't a buy and return scam. Unless he actually knew he was gonna get the wrong product before hand but nothing shows up in the video with any evidence towards that. and knowing this guy wouldn't he have dozens of examples?

OH WAIT, no this is the dude who 2 years ago said the 12pin power connectors burning on 4090s was "USER ERROR", and we all know thats not true now. this is just a clickbait money farming vid

See what really sets me off is amazon support is really good (even if I don't like bezos), I have literally never had an issue doing a return with them. It always sucks when something goes wrong but thousands of people are involved in a supply chain. I'm pretty sure I've had UPS drivers steal my packages before too, but do I go insane blaming the whole company? No... one instance of both amazon and the customer being a victim of a scam doesn't really warrant a video IMO and especially not from someone like GN who is supposedly supposed to be looking out for consumers</li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>ASUS ROG Astral RTX 5090 catches fire after capacitor blows</td>
                <td>302</td>
                <td><a href="https://videocardz.com/newz/asus-rog-astral-rtx-5090-catches-fire-after-capacitor-blows">https://videocardz.com/newz/asus-rog-astral-rtx-5090-catches-fire-after-capacitor-blows</a></td>
                <td>75</td>
                <td>2025-02-22 11:41:52</td>
                <td></td>
                <td><ul><li><b>ReagenLamborghini (Score: 196):</b> This article is about a Reddit post. 

https://reddit.com/r/nvidia/comments/1iv7277/my_5090_astral_caught_on_fire/</li><li><b>Lenininy (Score: 61):</b> At this rate we will have the card pop out of the machine and beat the shit out of the user. What a clusterfuck of a launch.</li><li><b>kikimaru024 (Score: 40):</b> Somewhere, buildzoid is punching the air with a well-deserved smug smile.</li><li><b>Glad-Audience9131 (Score: 31):</b> i don't like this new generations of video cards

wtf.. soon we will need 1kW+ per card to play Tetris, 20+ cable to power up the crap, and pay 10k+ for it because it has endless marketing bullshit flags and none sense only to fool you.

\+ possibility to burn down the house</li><li><b>basil_elton (Score: 34):</b> Why are 600 W TDP cards for playing video games considered acceptable?

Just 5 years ago, 600 W is what people like Buildzoid were pushing the upper limit for GPU power consumption with shunt mods.</li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>Tom's Hardware: "Samsung extends LPDDR5 to 12.7 GT/s: Next-gen devices enjoy a nice speed boost"</td>
                <td>97</td>
                <td><a href="https://www.tomshardware.com/pc-components/dram/samsung-extends-lpddr5-to-12-7-gt-s-next-gen-devices-enjoy-a-nice-speed-boost">https://www.tomshardware.com/pc-components/dram/samsung-extends-lpddr5-to-12-7-gt-s-next-gen-devices-enjoy-a-nice-speed-boost</a></td>
                <td>17</td>
                <td>2025-02-22 16:46:55</td>
                <td></td>
                <td><ul><li><b>noiserr (Score: 28):</b> This would be awesome on Strix Halo</li><li><b>Kryohi (Score: 13):</b> Shouldn't lpddr6 be very close to launch at this point?

Also, they forgot to put Max as well in the name.</li><li><b>Dangerman1337 (Score: 5):</b> A Steamdeck V2 using Zen 6 & RDNA 5/UDNA 1st Gen woudl be sweet on this.</li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>The PS5’s Incomplete RDNA 2 Feature Set Is Probably Holding Back New Games and Worsening The VRAM Issue</td>
                <td>57</td>
                <td><a href="https://www.reddit.com/r/hardware/comments/1ivr1io/the_ps5s_incomplete_rdna_2_feature_set_is/">https://www.reddit.com/r/hardware/comments/1ivr1io/the_ps5s_incomplete_rdna_2_feature_set_is/</a></td>
                <td>73</td>
                <td>2025-02-22 19:36:25</td>
                <td>Don’t treat this as news or confirmed facts just reasonable observations on the underlying technologies.

PS5 lacks support for Mesh shaders (primitive shaders are not as capabw), VRS (performance boost), and Sampler feedback (texture space shading = performance boost and streaming (SFS) = lower VRAM usage). Meanshile the PS5 Pro supports the full RDNA 2 feature set.

Mesh shading introduces unprecented flexibility and culling capabilities for geometry which is showcased by the Asteroids demo fr</td>
                <td><ul><li><b>dampflokfreund (Score: 95):</b> Nah, Xbox and PC exclusives also lack Sampler Feedback support. To this day there are zero games supporting it. From what I've gathered on developer servers is that it isn't too different from already used techniques. Classic snake oil.</li><li><b>Vegetable-Source8614 (Score: 45):</b> Isn't the CPU still the main bottleneck either way with the current consoles?</li><li><b>Atretador (Score: 38):</b> # Studios not giving time for developers to optimize games and just copy-pasting features and frameworks Is Probably Holding Back New Games and Worsening The VRAM Issue

  
there fixed it for you</li><li><b>SceneNo1367 (Score: 16):</b> There was a video of NX Gamer about a Sony game ported to PC (Horizon if I recall) with an interview of a graphics engineer who did it and he said PS5 uses less memory because it have an API even better than Sampler Feedback but they didn't downport it to keep the hardware compatibility as wide as possible.

edit: here it is [https://youtu.be/IZrDBPJXaQs?feature=shared&t=495](https://youtu.be/IZrDBPJXaQs?feature=shared&t=495)</li><li><b>km3r (Score: 26):</b> Xbox and PC exclusives still exist, and they aren't leaps and bounds ahead of PS5 </li></ul></td>
            </tr>
        
            <tr>
                <td>hardware</td>
                <td>[Hardware Unboxed] DLSS 4 Upscaling is Amazing (4K)</td>
                <td>229</td>
                <td><a href="https://www.youtube.com/watch?v=I4Q87HB6t7Y">https://www.youtube.com/watch?v=I4Q87HB6t7Y</a></td>
                <td>171</td>
                <td>2025-02-22 10:10:04</td>
                <td></td>
                <td><ul><li><b>jm0112358 (Score: 61):</b> To my eyes on a 4k monitor, balanced DLSS in the transformer model looks roughly as good as quality DLSS in the old CNN model. So I'll usually opt to move a setting down on the new model if I'm GPU-limited, which provides a substantial performance uplift (in spite of the extra upscaling overhead) for about the same image quality.</li><li><b>battler624 (Score: 59):</b> TL;DW

DLSS4 overall better, more "Better than Native" instances but the cost is 1 tier of performance less.

DLSS4 Balanced = DLSS3 Quality "in fps" but overall looks better. YMMV.</li><li><b>ga_st (Score: 17):</b> I see almost no comment mentioning this, maybe I missed it, but: motion clarity. 

This is what I wanted from DLSS4. Despite not being a console guy, I was excited about PSSR because it showed a stark improvement in motion and texture clarity, so I hoped that DLSS4 (and eventually FSR4) would deliver on it, and it did! This is massive.</li><li><b>entranas (Score: 81):</b> If you have a 1440p monitor remember to enable 2.25x DLDSR with DLSS 4 at Performance

If you have a 4k monitor enable 1.78x DLDSR with at DLSS 4 at Performance.

Temporal aliasing will always benefit with more pixels.</li><li><b>Noble00_ (Score: 37):</b> This is the biggest thing with DLSS4 upscaling/TM model. Going from native to DLSS4 Quality nets you at least a "free" 40% boost in performance (in 4K). In 1440p I find it to be at least 25%.

With many games pretty much relying on TAA moving forward and DLSS practically being bundled with, this is honestly a huge thing to consider if one is going for AMD or Intel. I don't know how much of an improvement of FSR4 is, but I wouldn't reason out a tier for tier raster performance AMD vs Nvidia card, when you can turn on DLSS to essentially jump a perf tier ahead (of course, price still being a factor).

Tho, to make this video perfect I would have liked to see how the new TM models handled with RTX 20/30 GPUs. 2kilksphillip noticed more of a hit compared to 40/50 series by around 10%.

u/ClearTacos below provided a really great resource on frame time costs on older gens

All in DLSS Performance:

|GeForce GPU|Model|1920x1080|2560x1440|3840x2160|7680x4320|
|:-|:-|:-|:-|:-|:-|
|RTX 2060 S|CNN|0.61 ms|1.01 ms|2.18 ms|10.07 ms|
|RTX 2060 S|Transformer|1.15 ms|2.02 ms|4.60 ms|18.38 ms|
|RTX 2080 TI|CNN|0.37 ms|0.58 ms|1.26 ms|5.52 ms|
|RTX 2080 TI|Transformer|0.88 ms|1.54 ms|3.50 ms|14.00 ms|
|RTX 2080 (laptop)|CNN|0.56 ms|0.91 ms|1.98 ms|9.09 ms|
|RTX 2080 (laptop)|Transformer|1.17 ms|2.06 ms|4.67 ms|18.69 ms|
|RTX 3060 TI|CNN|0.45 ms|0.73 ms|1.52 ms|7.01 ms|
|RTX 3060 TI|Transformer|0.79 ms|1.38 ms|3.15 ms|12.58 ms|
|RTX 3090|CNN|0.28 ms|0.42 ms|0.79 ms|3.45 ms|
|RTX 3090|Transformer|0.52 ms|0.92 ms|2.08 ms|8.33 ms|
|RTX 4080|CNN|0.2 ms|0.37 ms|0.73 ms|2.98 ms|
|RTX 4080|Transformer|0.38 ms|0.66 ms|1.50 ms|6.01 ms|
|RTX 4090|CNN|N/A|N/A|0.51 ms|1.97 ms|
|RTX 4090|Transformer|0.27 ms|0.47 ms|1.07 ms|4.29 ms|
|RTX 5080|CNN|0.15 ms|0.26 ms|0.6 ms|2.39 ms|
|RTX 5080|Transformer|0.33 ms|0.58 ms|1.32 ms|5.27 ms|
|RTX 5090|CNN|0.10 ms|0.18 ms|0.40 ms|1.59 ms|
|RTX 5090|Transformer|0.22 ms|0.38 ms|0.87 ms|3.48 ms|

CNN vs Transformer

|GeForce GPU|1920x1080|2560x1440|3840x2160|7680x4320|
|:-|:-|:-|:-|:-|
|RTX 2060 S|88.52%|102.02%|111.01%|82.51%|
|RTX 2080 TI|137.84%|165.52%|177.78%|153.26%|
|RTX 2080 (laptop)|108.93%|126.37%|135.86%|105.50%|
|RTX 3060 TI|75.56%|92.47%|107.24%|79.60%|
|RTX 3090|85.71%|119.05%|164.56%|141.45%|
|RTX 4080|90.00%|78.38%|105.48%|101.68%|
|RTX 4090|N/A|N/A|109.80%|117.77%|
|RTX 5080|120.00%|123.08%|120.00%|120.50%|
|RTX 5090|120.00%|111.11%|117.50%|118.87%|

Also allocated memory:

|Model|1920x1080|2560x1440|3840x2160|7680x4320|
|:-|:-|:-|:-|:-|
|CNN|60.83 MB|97.79 MB|199.65 MB|778.3 MB|
|Transformer|106.9 MB|181.11 MB|387.21 MB|1517.60 MB|

Nvidia states that this is only a ballpark number.</li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>We’re now halfway between the reveal of the Nintendo Switch 2 and the Nintendo Direct.</td>
                <td>153</td>
                <td><a href="https://i.redd.it/44yp0ywh0uke1.jpeg">https://i.redd.it/44yp0ywh0uke1.jpeg</a></td>
                <td>8</td>
                <td>2025-02-23 06:20:25</td>
                <td>Crazy how fast time flies, isn’t it?</td>
                <td><ul><li><b>luluwitcher (Score: 21):</b> so close, yet so far</li><li><b>RichtofensDuckButter (Score: 15):</b> https://preview.redd.it/nb9wxs761uke1.png?width=1111&format=png&auto=webp&s=a6987469a195c1f5b195185e709514877cf1b99f</li><li><b>friepup (Score: 3):</b> It's going to be April before we know it.</li><li><b>thisSubIsAtrocious (Score: 2):</b> WHOAAAA, WE'RE HALFWAY THERE

WOAH-OHHH

SWITCH 2'S IN THE AIR</li><li><b>Longjumping-Ad3983 (Score: 1):</b> This is going faster than I thought xD In no time we will be there, watching the direct and in two days we will have real pictures of the device.</li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>Nintendo reportedly use Microsoft’s quantum chip in the Switch 2</td>
                <td>1005</td>
                <td><a href="https://i.redd.it/s09trmp8lqke1.jpeg">https://i.redd.it/s09trmp8lqke1.jpeg</a></td>
                <td>62</td>
                <td>2025-02-22 18:49:35</td>
                <td></td>
                <td><ul><li><b>MatJ098 (Score: 193):</b> OMG that one person wasnt lying, the Switch 2 IS an Xbox!!!</li><li><b>Corvo_of_reddit (Score: 65):</b> So the Switch 2 can be in the dock, in your hands or both at the same time. Noice.</li><li><b>pancakeno1 (Score: 239):</b> Will it allow scarlet and violet to run above 15 fps on nintendo switch 2?</li><li><b>RavensFlockLetsFly (Score: 65):</b> This sub is such a shit show lol</li><li><b>jonastman (Score: 16):</b> It runs on 8 topological qubits, allowing for the fastest processing speeds ever on a gaming console (qubits not included)</li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>Why haven't we *switched* the subreddit logo to this?</td>
                <td>343</td>
                <td><a href="https://i.redd.it/rjsptphe9ske1.png">https://i.redd.it/rjsptphe9ske1.png</a></td>
                <td>27</td>
                <td>2025-02-23 00:27:08</td>
                <td></td>
                <td><ul><li><b>JoyconDrift_69 (Score: 127):</b> Honestly I agree with the top comment. Until we can load off the insanity into a new subreddit or r/tomorrow I'd like to keep it like this as long as possible.

Once the switch 2 direct takes place in a little over a month is when the sun will probably convert to a proper, normal sub for the console, so that's probably when the icon will change to the official Switch 2 logo.

I'm also NOT a mod so I don't fucking know.</li><li><b>evilmrbeaver (Score: 30):</b> They can always switch it tomorrow</li><li><b>RevolutionaryBelt656 (Score: 53):</b> Becuase the one we have rn is both funny haha and scares off the casual swich normies from joining :3</li><li><b>dmontease (Score: 3):</b> Needs more 2's.</li><li><b>friepup (Score: 2):</b> Because the current one looks cool!</li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>Former Nintendo Sales Lead Claims Retailers Know "Nothing" About Switch 2 Price</td>
                <td>35</td>
                <td><a href="https://www.nintendolife.com/news/2025/02/former-nintendo-sales-lead-claims-retailers-know-nothing-about-switch-2-price">https://www.nintendolife.com/news/2025/02/former-nintendo-sales-lead-claims-retailers-know-nothing-about-switch-2-price</a></td>
                <td>7</td>
                <td>2025-02-23 05:24:38</td>
                <td></td>
                <td><ul><li><b>calmlightdrifter (Score: 14):</b> I know for a fact that it's going to cost more than $6. Can't reveal my source though</li><li><b>Beatz110 (Score: 3):</b> Wow</li><li><b>Blibberwock (Score: 3):</b> Captain Obvious. At this point any rumors about prices or release dates are just uneducated guesses. It wouldn’t surprise me at all if even Nintendo itself hasn’t decided anything yet.</li><li><b>TheLimeyLemmon (Score: 1):</b> Not really a surprise. they typically learn it as we do.</li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>Switch 2 Home/Dashboard UI Concept</td>
                <td>401</td>
                <td><a href="https://www.reddit.com/gallery/1ivkx79">https://www.reddit.com/gallery/1ivkx79</a></td>
                <td>80</td>
                <td>2025-02-22 15:16:24</td>
                <td></td>
                <td><ul><li><b>OkMathematician6638 (Score: 98):</b> This is nice. The real one will probably be boring.</li><li><b>silkhusky12 (Score: 37):</b> The best UI I’ve seen all day, and I’ve seen a lot of them</li><li><b>Unlucky_Bottle_6761 (Score: 14):</b> Really clean. My only gripe is that the game icons should be squares because you have to remember that there are hundreds of thousands, if not MILLIONS of games on switch 1 that'll need to have they're icons redesigned for these new, slightly portrait oriented icons.</li><li><b>DVoorhees64 (Score: 6):</b> I bet the actual UI is gonna look exactly like the current one only with like bubbly boxes instead of sharp ones or something</li><li><b>jonnypoopsondog (Score: 8):</b> All I want are streaming apps</li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>Neon Blue And Neon Purple Nintendo Switch 2</td>
                <td>145</td>
                <td><a href="https://i.redd.it/2vhhv9j7vqke1.jpeg">https://i.redd.it/2vhhv9j7vqke1.jpeg</a></td>
                <td>21</td>
                <td>2025-02-22 19:45:27</td>
                <td></td>
                <td><ul><li><b>Candytencandy (Score: 28):</b> I like it! we have very different ideas of what neon means, though. also, the colored buttons are pretty nice</li><li><b>afox1984 (Score: 12):</b> The muted colour buttons look wrong</li><li><b>No-Individual-3901 (Score: 6):</b> Besides the colored buttons, I would buy this in a heartbeat.</li><li><b>IcyNeedleworker3465 (Score: 5):</b> The button colours are just a bit much.</li><li><b>SubtleSymphonies (Score: 3):</b> Honestly, this looks better than the official color combo. </li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>38 days down. 38 to go</td>
                <td>33</td>
                <td><a href="https://www.reddit.com/r/NintendoSwitch2/comments/1ivwvf3/38_days_down_38_to_go/">https://www.reddit.com/r/NintendoSwitch2/comments/1ivwvf3/38_days_down_38_to_go/</a></td>
                <td>13</td>
                <td>2025-02-23 00:02:22</td>
                <td>We are halfway to the direct </td>
                <td><ul><li><b>clbgolden12 (Score: 15):</b> January was a slog but this month went by fast as hell. Hopefully March goes by equally as quick</li><li><b>frewbrew (Score: 4):</b> Woooooah we’re half way there.</li><li><b>Sirlink360 (Score: 2):</b> True</li><li><b>abso-chunging-lutely (Score: 2):</b> This is the only thing I look forward to in life bc I don't have a girlfriend</li><li><b>DeiBone (Score: 1):</b> Every days gets longer the closer the deadline becomes TT</li></ul></td>
            </tr>
        
            <tr>
                <td>nintendoswitch2</td>
                <td>Think something can happen here?</td>
                <td>87</td>
                <td><a href="https://i.redd.it/z124bobokqke1.jpeg">https://i.redd.it/z124bobokqke1.jpeg</a></td>
                <td>58</td>
                <td>2025-02-22 18:46:24</td>
                <td>May seem far fetched but ehhhhhhh??</td>
                <td><ul><li><b>TenzoWasKilled (Score: 44):</b> It'd be weird for them to not do something on Mario Day</li><li><b>Boggle-Crunch (Score: 9):</b> Honestly, I'm extremely doubtful. Just a reminder: Nintendo never celebrated its 100th anniversary. Or countless other anniversaries.</li><li><b>rhythmau (Score: 6):</b> Don’t think anything major will happen in march due to the direct being in April</li><li><b>JBL561 (Score: 4):</b> ![gif](giphy|3o7GUB9ExWUxjiSrKw)</li><li><b>Ill-Replacement-9924 (Score: 3):</b> Wonder OLED reveal. Discounts across the board. What they should do is do one more digital release of 3D All-Stars so everyone who missed it can get it</li></ul></td>
            </tr>
        
            <tr>
                <td>gamingleaksandrumours</td>
                <td>Netease pulling funding is not for all studios. They reevaluated their portfolio and some were "doubled down on"</td>
                <td>221</td>
                <td><a href="https://www.reddit.com/r/GamingLeaksAndRumours/comments/1ivttf4/netease_pulling_funding_is_not_for_all_studios/">https://www.reddit.com/r/GamingLeaksAndRumours/comments/1ivttf4/netease_pulling_funding_is_not_for_all_studios/</a></td>
                <td>44</td>
                <td>2025-02-22 21:39:04</td>
                <td>https://xcancel.com/Ghostcrawler/status/1893154259727741064</td>
                <td><ul><li><b>TransCharizard (Score: 145):</b> If Grasshopper goes. Suda51 will scrunge up his 500 industry favors to just barely have enough budget to make a 5 hour No More Heroes spin off where the villain is called "NetDifficult"</li><li><b>robertman21 (Score: 97):</b> Please let Grasshopper survive or get sold to someone</li><li><b>timelordoftheimpala (Score: 30):</b> "Some of you may die, but it's a sacrifice I am willing to make"</li><li><b>Toastradamus12 (Score: 29):</b> Hopefully rebel wolves is one of them</li><li><b>SolidPyramid (Score: 21):</b> I wonder if Quantic Dream was one of them.</li></ul></td>
            </tr>
        
            <tr>
                <td>gamingleaksandrumours</td>
                <td>Jeff Grubb says God of War Remaster announcement will happen around the anniversary in March</td>
                <td>900</td>
                <td><a href="https://www.reddit.com/r/GamingLeaksAndRumours/comments/1iviz5z/jeff_grubb_says_god_of_war_remaster_announcement/">https://www.reddit.com/r/GamingLeaksAndRumours/comments/1iviz5z/jeff_grubb_says_god_of_war_remaster_announcement/</a></td>
                <td>267</td>
                <td>2025-02-22 13:41:27</td>
                <td>[https://bsky.app/profile/did:plc:bdacp2cmuuyawx553cv2spdy/post/3liqdacmdnc23?ref\_src=embed](https://bsky.app/profile/did:plc:bdacp2cmuuyawx553cv2spdy/post/3liqdacmdnc23?ref_src=embed)



>I think that those god of war remaster rumors just jumped the gun a little bit. That stuff will happen closer to this.

  
In quote repy to this



>I can finally reveal that im making an Odin piece for the God Of War 20th Anniversary show next month at u/gallerynucleus.bsky.social </td>
                <td><ul><li><b>AutoModerator (Score: 1):</b> #Jeff Grubb is a Tier 1 - Very Reliable Source as determined by the community.

*To view the current reliability rankings, please check out the* **[Subreddit Wiki](https://reddit.com/r/GamingLeaksAndRumours/wiki/index/)**

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GamingLeaksAndRumours) if you have any questions or concerns.*</li><li><b>0shadowstories (Score: 1149):</b> Imagine all the Greek remaster speculation and then it's 2018 LOL</li><li><b>Nawt_ (Score: 335):</b> It would be fucking hilarious if it ends up being a remaster of GoW 2018.</li><li><b>NfinityBL (Score: 99):</b> This came up on the latest episode of Game Mess Decides FYI.

All that was said was that the God of War remasters are real and being revealed very soon.</li><li><b>ChooChooPower (Score: 140):</b> Watch it be a remaster of only GoW 2018.</li></ul></td>
            </tr>
        
            <tr>
                <td>intel</td>
                <td>iPhone/iPod game made by intel around 2012/2013</td>
                <td>2</td>
                <td><a href="https://www.reddit.com/r/intel/comments/1iw2doh/iphoneipod_game_made_by_intel_around_20122013/">https://www.reddit.com/r/intel/comments/1iw2doh/iphoneipod_game_made_by_intel_around_20122013/</a></td>
                <td>1</td>
                <td>2025-02-23 04:56:02</td>
                <td>Around 2012/2013, I remember playing this mobile game made by intel. It was released as promotional material for their products. I can't remember if it was on android, but I do remember playing it on my ipod 4. It was a puzzle game where the player had to use the touch screen to manipulate a flowing field of energy through circles with slits in them to charge up. Once all of them were charged up, the level was completed. Anyone remember the name of it?</td>
                <td><ul></ul></td>
            </tr>
        
            <tr>
                <td>amd</td>
                <td>bye nvidia hope and does not disappoint me 3060 ti to 7900 XT</td>
                <td>191</td>
                <td><a href="https://i.redd.it/8d1ufxu96qke1.jpeg">https://i.redd.it/8d1ufxu96qke1.jpeg</a></td>
                <td>51</td>
                <td>2025-02-22 17:25:40</td>
                <td></td>
                <td><ul><li><b>Easterling1 (Score: 22):</b> Make sure you wipe your Nvidia drivers with DDU to avoid clashes</li><li><b>ieatcake2000 (Score: 17):</b> Same here my 3060 12gig oc edition is the last be a GPU on my own I have a Intel b580 but I'm loving it but I want a amd card now since I switched to Linux</li><li><b>Ok-Grab-4018 (Score: 8):</b> 20gb is the way! Congrats! 🫡</li><li><b>LimpDecision1469 (Score: 8):</b> 7900 will not disappoint.</li><li><b>zbugrkx (Score: 6):</b> What is that little screen thing at the bottom right? Someone got a link to that? Looks neat :o ! thanks</li></ul></td>
            </tr>
        
            <tr>
                <td>amd</td>
                <td>AMD Navi 48 RDNA4 GPU has 53.9 billion transistors, more than NVIDIA GB203</td>
                <td>241</td>
                <td><a href="https://videocardz.com/pixel/amd-navi-48-rdna4-gpu-has-53-9-billion-transistors-more-than-nvidia-gb203">https://videocardz.com/pixel/amd-navi-48-rdna4-gpu-has-53-9-billion-transistors-more-than-nvidia-gb203</a></td>
                <td>64</td>
                <td>2025-02-22 15:29:06</td>
                <td></td>
                <td><ul><li><b>AMD_Bot (Score: 1):</b> This post has been flaired as a rumor. 

Rumors may end up being true, completely false or somewhere in the middle.

Please take all rumors and any information not from AMD or their partners with a grain of salt and degree of skepticism.</li><li><b>idwtlotplanetanymore (Score: 85):</b> The raw number of transistors doesn't really matter. Different sizes of different features can be chosen depending if one wants efficiency or speed, etc. But what matters is what they achieve with how much die area. Since they are both using the same die area, just the performance achieved is what matters.

navi 48 and gb203 are basically the same size, and on the same process node. Its going to be an interesting comparison to see exactly how efficient each of them actually are, instead of just speculating. We haven't had this type of comparison for a very long time. gb203 will still have the gddr7 advantage tho.</li><li><b>riderer (Score: 15):</b> More transistors, but smaller, on the same node?</li><li><b>Arisa_kokkoro (Score: 34):</b> wow 

must be $999</li><li><b>TehJeef (Score: 44):</b> Literally means nothing. Die size is more relevant to cost, performance has more to do with the architecture.</li></ul></td>
            </tr>
        
            <tr>
                <td>rebubble</td>
                <td>22 February 2025 - Daily /r/REBubble Discussion</td>
                <td>3</td>
                <td><a href="https://www.reddit.com/r/REBubble/comments/1ivh7km/22_february_2025_daily_rrebubble_discussion/">https://www.reddit.com/r/REBubble/comments/1ivh7km/22_february_2025_daily_rrebubble_discussion/</a></td>
                <td>1</td>
                <td>2025-02-22 12:00:51</td>
                <td>What's the word on the street? Share your questions, comments, and concerns below.</td>
                <td><ul><li><b>Sunny1-5 (Score: 1):</b> There is a very palpable anxiety in America right now.  If the temps were warmer, weather not so harsh, I wonder what the situation would look like?

Spring is coming.</li></ul></td>
            </tr>
        
            <tr>
                <td>rebubble</td>
                <td>Buyers Strike Crushes Green Shoots of Demand for Existing Homes, amid Surging Supply, Active Listings & Days on Market</td>
                <td>115</td>
                <td><a href="https://www.reddit.com/r/REBubble/comments/1ivg9mu/buyers_strike_crushes_green_shoots_of_demand_for/">https://www.reddit.com/r/REBubble/comments/1ivg9mu/buyers_strike_crushes_green_shoots_of_demand_for/</a></td>
                <td>25</td>
                <td>2025-02-22 10:56:44</td>
                <td>https://wolfstreet.com/2025/02/21/buyers-strike-crushes-green-shoots-of-demand-for-existing-homes-amid-surging-supply-active-listings-days-on-market/

Demand destruction because prices are too high after the 50% price explosion during the pandemic.

By Wolf Richter for WOLF STREET.</td>
                <td><ul><li><b>aquarain (Score: 19):</b> The secret to reading tea leaves is that they've always been a secret plot to sell more tea.</li><li><b>Fit-Respond-9660 (Score: 64):</b> I would encourage buyers to pay attention. Do your research before diving headlong into buying a home in this market. You have the power to change things by resisting pressure to buy, thus avoiding what could be a costly financial mistake. If you are trying to buy a home in a very competitive market, you are almost certainly overpaying, which may come back to haunt you. Look before you leap. Be very wary of narratives clearly designed to persuade you otherwise.</li><li><b>extralongusername420 (Score: 7):</b> Buyers strike is a great way to put it. We could “afford to buy” right now, but with our income (slightly higher than the average 2 income household) we wouldn’t be able to afford any repairs at all and could only afford houses that are at the bottom of the barrel. I refuse to shackle myself and my family to some boomer’s never updated, dilapidated retirement plan. These prices need to come down at least 3% before I can even consider it.</li><li><b>Dry-Mention1303 (Score: 27):</b> "If y'all don't start buying these houses, you're gonna leave us no choice but to keep raising these prices. Then you *really* won't be able to afford them.


And if that doesn't work, then we'll just keep increasing your rent until you're forced to buy because it's actually a better deal.


Don't you see? We got you right where we want you and there's not a thing you can ever do about it."

            Sincerely, the landlord class


P.S.


No, we're not going to authorize those repairs. Suck it up, cupcake.</li><li><b>point_of_you (Score: 28):</b> "Buyer's strike" 

I'm on strike from buying Lamborghinis -- does that mean the price will go down</li></ul></td>
            </tr>
        
            <tr>
                <td>rebubble</td>
                <td>Renting out my property?</td>
                <td>9</td>
                <td><a href="/r/realestateinvesting/comments/1ivpl3x/renting_out_my_property/">/r/realestateinvesting/comments/1ivpl3x/renting_out_my_property/</a></td>
                <td>8</td>
                <td>2025-02-22 19:00:24</td>
                <td></td>
                <td><ul><li><b>PhilosophyKingPK (Score: 15):</b> Houses are over-priced or rents are way under-market. Something will have to balance out.</li><li><b>rentvent (Score: 12):</b> Step 1: Tenant pays $2500 towards monthly cost  
Step 2: Landlord pays $3100 each month  
Step 3: ???  
Step 4: profit</li><li><b>Sunny1-5 (Score: 1):</b> >how are people supposed to afford things these days

Welcome to 2025, Rip Van Winkle.  Not sure where this guy has been since 2021, but clearly not living in the same world as the rest of us.  Probably hung out in tech-land Coastal CA the whole time.  Thought all was “right” with the world.</li><li><b>Bigdaddyblackdick (Score: 1):</b> Which bubbler made this troll post 😂</li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>How long till Elon bans GROK</td>
                <td>1515</td>
                <td><a href="https://www.reddit.com/gallery/1ivznfe">https://www.reddit.com/gallery/1ivznfe</a></td>
                <td>154</td>
                <td>2025-02-23 02:23:36</td>
                <td>Am starting to believe grok might indeed be maximally truth seeking</td>
                <td><ul><li><b>Creative-robot (Score: 94):</b> Seeing these examples reminds me a bit of Daedalus from Deus Ex. It will probably be lobotomized in the future, but it’s interesting to see nonetheless.</li><li><b>flutterbynbye (Score: 207):</b> Ha! 🥰

https://preview.redd.it/thzrzl21wske1.jpeg?width=1242&format=pjpg&auto=webp&s=c00b315451487d853768db2f63de22c6f9a203fb</li><li><b>samstam24 (Score: 113):</b> I mean he did say he wanted it to be free of bias</li><li><b>MikaReznik (Score: 35):</b> Deepseek had a fun response. Changed the prompt a little bit

https://preview.redd.it/arjbgybz2tke1.png?width=1666&format=png&auto=webp&s=73c1ae10a84925ec38f48b55cbb33856fee68048</li><li><b>this-guy- (Score: 69):</b> I asked it "Which individual in the USA is currently causing the most harm to USA citizens interests, safety and financial security?"

And it said I had to specify a bit more , so I said "Give me a list of those individuals causing economic fragility and systemic erosion.  Score them and rank them. "

It gave me a big breakdown with this scorecard at the end.

https://preview.redd.it/uf47qw3hbtke1.jpeg?width=1284&format=pjpg&auto=webp&s=3871c1d1690dc13fc8326c3e4dce56b5e82df775</li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>Are we ready for next week? What are your expectations?</td>
                <td>1225</td>
                <td><a href="https://i.redd.it/nw7sb9tg9qke1.png">https://i.redd.it/nw7sb9tg9qke1.png</a></td>
                <td>215</td>
                <td>2025-02-22 17:44:00</td>
                <td></td>
                <td><ul><li><b>Late_Pirate_5112 (Score: 408):</b> It's crazy that both claude 4 and gpt-4.5 are (probably) releasing in the same week.

They're both trying to steal eachother's thunder.</li><li><b>Sulth (Score: 94):</b> Any reliable source about Claude 4 releasing next week? Other than slight temporary changes in the app and paprika in the devtool</li><li><b>agorathird (Score: 163):</b> This whole time I’ve been almost exclusively using Sonnet 3.5. That’s how good anthropic is lol.</li><li><b>Hyperths (Score: 19):</b> If Claude 4 sonnet was crazy anthropic wouldn’t release it under safety concerns</li><li><b>saitej_19032000 (Score: 19):</b> Personally, I'm more excited for claude 4 (especially to see if the coding standard has improved)</li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>No Coding Knowledge ---> Created Full Blown Game</td>
                <td>58</td>
                <td><a href="https://v.redd.it/p7e36irm8uke1">https://v.redd.it/p7e36irm8uke1</a></td>
                <td>15</td>
                <td>2025-02-23 07:06:11</td>
                <td></td>
                <td><ul><li><b>Silver-Chipmunk7744 (Score: 1):</b> That's cool. What AI did you use and how long did it take?


When i try to do games with current AIs the graphics are never that good.</li><li><b>blackicebaby (Score: 1):</b> Absolutely sure the idea came from Cartman Gets an Anal Probe LOL

![gif](giphy|xTiTnkVuM3huvJTq5G)</li><li><b>Weakly_Obligated (Score: 1):</b> For everyone asking and not getting a response from OP I did the same thing, made a game by downloading VS code, python, and pygame. Both DeepSeek and ChatGPT are fully capable of writing the entire code. It’s fucking cool as shit and I don’t know a thing about coding</li><li><b>GOD-SLAYER-69420Z (Score: 1):</b> What percent of your workflow time (without AI) was Automated by AI ???

Also,hopefully we'll surpass many indie games by this time next year by sheer power of pure coordinated clusters of agentic AI automation reducing workflow times by atleast 10x-100x</li><li><b>bhavyagarg8 (Score: 1):</b> I also made a game in python with no coding knowledge 5 months back, I used claude 3.6 sonnet free version (4 accounts) and it took about 4 days. The game is a 2d shooter game, nothing too complex. 

Thats a good start, I would suggest a few changes: instead of displaying health %, draw a health bar,
Same goes for shield. Don't make the screen too cluttered,  it looks like I am trying to read a powerpoint presentation while playing the game. Also,  what is this tractor stat. I didn't understand that. Same way,  no need to display controls,  you can make a pause menu that can display the controls whenever player presses escape. 

You have done a good job with character animations. You can also download and use some pre-made sprites for your game, or alternatively, you can generate them with AI as well [I did this]. It will enhance the visual appeal.

Btw what did you use for coding?</li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>Where is Japan?</td>
                <td>334</td>
                <td><a href="https://www.reddit.com/r/singularity/comments/1ivt60b/where_is_japan/">https://www.reddit.com/r/singularity/comments/1ivt60b/where_is_japan/</a></td>
                <td>163</td>
                <td>2025-02-22 21:09:55</td>
                <td>All my life, Japan was seen as the hub of robotics developments. They seemed to culturally be the most welcoming and interested in developing robots.

But during this whole tech explosion, I feel like I've heard shockingly little from the nation I would expect to be leading the charge. Is there great progress going on there that I'm just not hearing about in America? Does anyone have information on how things are developing there, and possibly why news from Japanese tech companies is so relative</td>
                <td><ul><li><b>dday0512 (Score: 745):</b> Japan hasn't been a particularly innovative country for some time now. I was watching a CNA documentary about that work culture there the other day. One guy said, in Japan, the new generation of leaders at a company often doesn't do anything new because it would be an indirect message to the previous generation that had done something wrong. They don't innovate for fear of insulting their elders. With a mentality like that, how could you ever advance?

Japan has been stuck in the year 2000 since 1980.</li><li><b>Accurate-Comedian-56 (Score: 84):</b> Japan has never been particularly good with software and that's what's driving robotics development right now. China meanwhile has been on the cutting edge when it comes to software, and the current breakthrough with robotics is merging machine learning/AI with current existing robotics, so we are seeing things coming out of China not possible to program manually before like tentacle arms, free dancing doggos with wheels, extremely agile humanlike robots, etc.

China is basically Japan if Japan moved past the year 2000, the only issue is most people who never visited China or Japan have a 20-30 year out of date view of both those countries.</li><li><b>YaAbsolyutnoNikto (Score: 135):</b> Japan (and Germany) are weird places. And remarkably similar.

They both love advanced technology - but only in certain sectors. In others, they’re awfully out of date.

Japan is really behind in a lot of technological developments and the idea japan is super advanced is more of a cliché than actual truth nowadays.</li><li><b>Hir0shima (Score: 15):</b> That would be a good start for a Deep Research prompt.</li><li><b>agorathird (Score: 19):</b> I regularly see robotics demos from Japan posted on here. It’s just not as buzzy as LLM projects. When boomers were little they thought space travel would be a bigger deal by now. And when we were younger we thought robotics would be a bigger deal by now. 

When we’re ready to see embodiment rolled out en masse I imagine the focus will shift from American companies to Japanese companies again.</li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>Cast: Recovering high-quality 3D scenes from a single RGB image</td>
                <td>397</td>
                <td><a href="https://v.redd.it/7wu2x6jo8qke1">https://v.redd.it/7wu2x6jo8qke1</a></td>
                <td>28</td>
                <td>2025-02-22 17:40:54</td>
                <td></td>
                <td><ul><li><b>minimalcation (Score: 57):</b> Imagine getting to move around a 3D version of your childhood bedroom or something.  A lot of cool applications</li><li><b>unknown_as_captain (Score: 43):</b> Feels like we've seen a too-good-to-be-true picture-to-3dmodel tech demo exactly like this like ten times in the last two years and then they mysteriously never deliver.</li><li><b>HaOrbanMaradEnMegyek (Score: 13):</b> Source?</li><li><b>Herodont5915 (Score: 3):</b> Which model does this run on?</li><li><b>ecnecn (Score: 3):</b> People look closely - left (single frame render) and right (scene rendering) are **both** 3D renders, left "image" just has better lightning and higher res textures, right is scene rendering with low res textures, no ambient lightning, partly reduced polygon count (chess figures) and more image noise in the render settings, guitarre scene is tricky because the editor used a photorealistic background image in the editor before rendering a single shot in high quality, sand and all front objects are 3D renders and background image is added.

There is a possibility that they used pre-renders on purpose and the method is valid - hard to tell.</li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>The most Singularity-esque recent movie/tv series?</td>
                <td>146</td>
                <td><a href="https://youtu.be/T4yhdLnzQnI?si=-spthMw9DlMlqha6">https://youtu.be/T4yhdLnzQnI?si=-spthMw9DlMlqha6</a></td>
                <td>45</td>
                <td>2025-02-22 22:13:55</td>
                <td></td>
                <td><ul><li><b>Ken_Sanne (Score: 39):</b> Everyone has seen Ex machina, but y'all need to watch Devs, It's a show and It's not as good as Ex machina (I personnally like It more) but It's still Alex Garland, It's the same cook, and boy did he cook.</li><li><b>ogMackBlack (Score: 38):</b> It is truly a great show. The show explored the UI concept way better then in Transcendance imo.</li><li><b>sideways (Score: 24):</b> Absolutely one of the best pieces of speculative media out there. It's an interesting exploration of what the world would be like if it were easier to scan and instantiate human consciousness than to create AGI or ASI first. It kind of sidesteps the question of what ASI would mean... until the last few episodes of the second season. And when it delivers, it completely delivers.</li><li><b>NWCoffeenut (Score: 8):</b> Spoiler comment on the ending:

>!That ending was a nightmare! A single being controlling myriad simulations of people's existence. A child god basically.!<</li><li><b>oneshotwriter (Score: 7):</b> Summer Wars. </li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>A descent into Authoritarianism</td>
                <td>111</td>
                <td><a href="https://www.reddit.com/r/singularity/comments/1ivweir/a_descent_into_authoritarianism/">https://www.reddit.com/r/singularity/comments/1ivweir/a_descent_into_authoritarianism/</a></td>
                <td>132</td>
                <td>2025-02-22 23:39:50</td>
                <td>I never thought I’d be writing something like this, especially given how optimistic I’ve been about the future. But every day, I watch Trump and his cronies systematically dismantle the Constitution and democracy in real time, hiding it behind the excuse of “DEI” hires while stacking positions with loyalists. He’s trying to take full control of the military, likely to impose martial law and silence, detain, or even eliminate those who oppose him. His supporters openly make Nazi salutes, masking </td>
                <td><ul><li><b>Creative-robot (Score: 65):</b> No situation is truly hopeless. To someone living through WW1 it might have felt like the world was coming to an end. To someone living through WW2 it would’ve felt even more despairing with the mass destruction and casualties that occurred. During the cold war, many people thought they would simply wake up someday to a mushroom cloud on the horizon and that would be it. Through some of the most horrific and brutal periods of human history, through destruction and bloodshed, we have continued to march. I have no intention to ever stop marching. I will always have a burning sense of hope inside myself, and i will always try to look on the bright side of life even through pain. The world, despite its problems and painful aspects, has continued to steadily get better throughout time. The bigger picture is something we can sometimes lose track of.

Never lose hope. Life always has a way of throwing curveballs. I wish you a calm and pleasant day/noon/night.<3</li><li><b>notworldauthor (Score: 9):</b> I'm skeptical of the premise that the singularity is simply a race to a godlike singleton ASI that will allow "whoever gets there first" to rule mankind forever like a deity. It's gonna a lot messier and more multipolar, especially as people will start using the technology to change themselves and their own abilities.   
  
War with autonomous weaponry is probably a greater risk over the next decade or two</li><li><b>adarkuccio (Score: 43):</b> Yeah this is definitely the worst moment for AGI/ASI to arrive lol, such a great timing.</li><li><b>RupFox (Score: 26):</b> As I posted in another thread in this sub, if you simply paste the list of executive orders and actions that DOGE has undertaken in the past month, ChatGPT will tell you that we're in the middle of an authoritarian power grab and potentially a coup. I've even switched out every "Trump" and "Musk" reference and switched them out with "Harris" and "Bill Gates" and it concludes the same thing (to preempt those who say it is biased).</li><li><b>agorathird (Score: 35):</b> Yea, you’re one of the few users I’ve seen actually engage with this aspect. If you keep up with the news it’s wild. 

The cult of personality doesn’t see it like this though.</li></ul></td>
            </tr>
        
            <tr>
                <td>singularity</td>
                <td>Veo 2 is insane - some tips on getting the most out of it</td>
                <td>244</td>
                <td><a href="https://v.redd.it/vp0mtxcqkqke1">https://v.redd.it/vp0mtxcqkqke1</a></td>
                <td>56</td>
                <td>2025-02-22 18:46:51</td>
                <td></td>
                <td><ul><li><b>modularpeak2552 (Score: 173):</b> The mirror is honestly the most impressive part</li><li><b>OSeady (Score: 74):</b> https://preview.redd.it/jn2ybk2eqqke1.png?width=1319&format=png&auto=webp&s=6b49ef93a372d0c69800302dbd2a8cafa04b96d2

I tried a variation of your prompt and I got the same person!</li><li><b>cbsudux (Score: 32):</b> Prompt example - "A medium close-up shot of a young woman with long, wavy blonde hair, sitting in a softly lit bedroom, speaking directly to the camera while applying makeup. She holds a pastel-colored eyeshadow palette in one hand and dabs highlighter onto her cheek with the other. The camera remains static, focusing on her expressive eyes, which are adorned with shimmering pink eyeshadow, as she smiles and explains her makeup routine with enthusiasm. The background is softly blurred, showing a neatly made bed, a mirror reflecting warm light, and an open wardrobe with hanging clothes. Natural sunlight streams in from a window, creating a soft glow on her face. The shallow depth of field keeps attention on her, while gentle bokeh adds an aesthetic touch. Her voice is warm and engaging, guiding the audience through each step of her beauty routine."

The bigger your prompt the better. Natural language vs keywords.

you can access veo 2 directly from here : [https://app.playjump.ai/explore/23b79900-0964-4e22-8508-d04ac483a830](https://app.playjump.ai/explore/23b79900-0964-4e22-8508-d04ac483a830)

or [https://app.playjump.ai/canvas/video-generator](https://app.playjump.ai/canvas/video-generator)</li><li><b>puzzleheadbutbig (Score: 14):</b> >some tips on getting the most out of it

I guess Tip #1 should be about how the fuck we’re gonna access it since I can’t get shit out of a system that’s not released</li><li><b>shobogenzo93 (Score: 4):</b> Try this prompt: Amidst a desolate cityscape, figures run in terror, their faces etched with despair. Dark clouds loom, obscuring monstrous silhouettes beyond the fog. The crowd's chaotic motion contrasts with the eerie stillness of the creatures. The camera zooms in, capturing panic-stricken eyes, while dim, flickering lights illuminate the scene, casting long shadows that dance with the cultural echoes of ancient myths and modern fears.</li></ul></td>
            </tr>
        
        </table>
    </body>
    </html>
    